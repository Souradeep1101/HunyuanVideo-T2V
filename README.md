# HunyuanVideo-T2V

HunyuanVideo-T2V is an implementation of the *HunYuanVideo* research paper using PyTorch. The project focuses on building a scalable pipeline for **Text-to-Video (T2V)** generation using diffusion models, transformers, and multimodal language models.

## ğŸ“‚ Project Structure
```
HunyuanVideo-T2V/
â”œâ”€â”€ data/                     # Raw and processed datasets
â”œâ”€â”€ models/                   # Model architecture files
â”œâ”€â”€ scripts/                  # Data processing and training scripts
â”œâ”€â”€ configs/                  # Configuration files (model, data, training)
â”œâ”€â”€ utils/                    # Helper functions (e.g., video processing, embeddings)
â”œâ”€â”€ logs/                     # Training and processing logs
â”œâ”€â”€ checkpoints/              # Model checkpoints
â”œâ”€â”€ outputs/                  # Generated videos and results
â”œâ”€â”€ notebooks/                # Jupyter notebooks for experimentation
â”œâ”€â”€ environment.yml           # Conda environment dependencies
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ main.py                   # Entry point (if required later)
â””â”€â”€ LICENSE                   # MIT License
```

## ğŸ›  Features
- **Video Preprocessing**: Automatic splitting, frame extraction, and deduplication.
- **Caption Generation**: Structured captions using BLIP-2 or LLaVA.
- **Model Training**: Progressive learning from images to videos.
- **Text-to-Video Generation**: Uses diffusion models for high-quality video generation.

## ğŸ”§ Setup

### 1. Clone the repository
```bash
git clone https://github.com/Souradeep1101/HunyuanVideo-T2V.git
cd HunyuanVideo-T2V
```

### 2. Set up the environment
#### Using Conda:
```bash
conda env create -f environment.yml
conda activate hunyuanvideo-t2v
```
#### Or using pip:
```bash
pip install -r requirements.txt
```

### 3. Run the scripts
- **Preprocess videos**:
  ```bash
  python scripts/preprocess_videos.py
  ```
- **Generate captions**:
  ```bash
  python scripts/generate_captions.py
  ```

## ğŸ“Š Results
Add example outputs or showcase generated videos here.

## ğŸ“œ License
This project is licensed under the [MIT License](LICENSE).

---

## ğŸ¤ Contributing
Contributions, issues, and feature requests are welcome! Feel free to check the [issues page](https://github.com/<your-username>/HunyuanVideo-T2V/issues).

## ğŸ“§ Contact
For any inquiries or feedback, please reach out to **rishibanerjee1101@gmail.com**.

---

## â­ Acknowledgments
This project is inspired by the *HunYuanVideo* research paper and builds on state-of-the-art technologies like PyTorch, BLIP-2, and diffusion models.
